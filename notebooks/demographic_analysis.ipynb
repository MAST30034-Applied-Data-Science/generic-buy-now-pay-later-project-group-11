{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Customer Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/05 15:28:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2 BNPL\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening 'BNPL' dataset\n",
    "merchants = spark.read.parquet(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/tbl_merchants.parquet\")\n",
    "consumer = spark.read.csv(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/tbl_consumer.csv\", header=True, sep=\"|\")\n",
    "details = spark.read.parquet(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added Documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added Documents\n"
     ]
    }
   ],
   "source": [
    "# load all transactions datasets\n",
    "paths=['/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/transactions_20210228_20210827_snapshot',\n",
    "       '/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/transactions_20210828_20220227_snapshot']\n",
    "\n",
    "first = 1\n",
    "for path in paths:\n",
    "    if first:\n",
    "        transactions = spark.read.parquet(path)\n",
    "        print(f'added {path.split(\"/\")[3]}')\n",
    "        first = 0\n",
    "    else:\n",
    "        append_transactions = spark.read.parquet(path)\n",
    "        transactions = transactions.union(append_transactions)\n",
    "        print(f'added {path.split(\"/\")[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "merchants = merchants.withColumnRenamed('name', 'merchant_name')\n",
    "consumer = consumer.withColumnRenamed('name', 'consumer_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join consumers with their respective details\n",
    "consumer_detail = consumer.join(details, on=\"consumer_id\")\n",
    "\n",
    "# Join consumers with their respective transactions\n",
    "consumer_trx = consumer_detail.join(transactions, on=\"user_id\")\n",
    "\n",
    "# Join transactions with the respective merchants\n",
    "df_trx = consumer_trx.join(merchants, on=\"merchant_abn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Consumer gender proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Opening 'tbl_consumer.csv' dataset\n",
    "consumer = spark.read.csv(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/tbl_consumer.csv\", header=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 384:========>        (1 + 1) / 2][Stage 386:====>            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|     gender|\n",
      "+-----------+\n",
      "|Undisclosed|\n",
      "|     Female|\n",
      "|       Male|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 384:============================>                            (1 + 1) / 2]\r"
     ]
    }
   ],
   "source": [
    "# Find distinct values on the 'gender' column\n",
    "consumer.select('gender').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.989289978579954"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the proportion on each of the distinct values in 'gender' (on percentage)\n",
    "total_consumer = consumer.select('gender').count()\n",
    "female_proportion = (consumer.select('gender').where(consumer.gender=='Female').count() / total_consumer)*100\n",
    "male_proportion = (consumer.select('gender').where(consumer.gender=='Male').count() / total_consumer)*100\n",
    "undisclosed_proportion = (consumer.select('gender').where(consumer.gender=='Undisclosed').count() / total_consumer)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Calculate proportion of merchants level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening 'BNPL' dataset\n",
    "merchants = spark.read.parquet(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/tbl_merchants.parquet\")\n",
    "consumer = spark.read.csv(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/tbl_consumer.csv\", header=True, sep=\"|\")\n",
    "details = spark.read.parquet(\"/Users/roseline/Documents/GitHub/generic-buy-now-pay-later-project-group-11/data/tables/consumer_user_details.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|level|\n",
      "+-----+\n",
      "|e    |\n",
      "|b    |\n",
      "|b    |\n",
      "|b    |\n",
      "|a    |\n",
      "|a    |\n",
      "|b    |\n",
      "|c    |\n",
      "|a    |\n",
      "|a    |\n",
      "|a    |\n",
      "|b    |\n",
      "|b    |\n",
      "|b    |\n",
      "|a    |\n",
      "|a    |\n",
      "|a    |\n",
      "|b    |\n",
      "|a    |\n",
      "|c    |\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 389:============================>                            (1 + 1) / 2]\r"
     ]
    }
   ],
   "source": [
    "# Extracting the merchants level from 'tags' column\n",
    "from pyspark.sql.functions import substring, length, col, expr\n",
    "merchants = merchants.withColumn('temp_level',expr(\"substring(tags, 1, length(tags)-21)\"))\n",
    "merchants = merchants.withColumn('level', merchants.temp_level.substr(-1,1))\n",
    "merchants.select('level').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|level|\n",
      "+-----+\n",
      "|    e|\n",
      "|    d|\n",
      "|    c|\n",
      "|    b|\n",
      "|    a|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merchants.select('level').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of merchants level\n",
    "total_merchants = merchants.count()\n",
    "merchants_level_a = (merchants.select('level').where(merchants.level == 'a').count() / total_merchants)*100\n",
    "merchants_level_b = (merchants.select('level').where(merchants.level == 'b').count() / total_merchants)*100\n",
    "merchants_level_c = (merchants.select('level').where(merchants.level == 'c').count() / total_merchants)*100\n",
    "merchants_level_d = (merchants.select('level').where(merchants.level == 'd').count() / total_merchants)*100\n",
    "merchants_level_e = (merchants.select('level').where(merchants.level == 'e').count() / total_merchants)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transaction Frequency (Monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------------+------------------------------------+--------------+----+-----+----+\n",
      "|user_id|merchant_abn|dollar_value      |order_id                            |order_datetime|year|month|date|\n",
      "+-------+------------+------------------+------------------------------------+--------------+----+-----+----+\n",
      "|18478  |62191208634 |63.255848959735246|949a63c8-29f7-4ab0-ada4-99ac50a88952|2021-08-20    |2021|08   |20  |\n",
      "|2      |15549624934 |130.3505283105634 |6a84c3cf-612a-4574-835b-144a47353eff|2021-08-20    |2021|08   |20  |\n",
      "|18479  |64403598239 |120.15860593212783|b10dcc33-e53f-4254-863c-de5266810cbc|2021-08-20    |2021|08   |20  |\n",
      "|3      |60956456424 |136.6785200286976 |0f09c5a5-784e-4477-b049-8ee4dd069b7b|2021-08-20    |2021|08   |20  |\n",
      "|18479  |94493496784 |72.96316578355305 |f6c78c1a-4600-4c5f-8e97-6e9eb534b586|2021-08-20    |2021|08   |20  |\n",
      "|3      |76819856970 |448.529684285612  |5ace6a24-cdf0-4aa3-b571-1d9406b352b5|2021-08-20    |2021|08   |20  |\n",
      "|18479  |67609108741 |86.4040605836911  |d0e180f0-cb06-42a3-bd1a-c47dca15bc55|2021-08-20    |2021|08   |20  |\n",
      "|3      |34096466752 |301.5793450525113 |6fb1ff48-24bb-4f97-9a96-d2e8ca009bda|2021-08-20    |2021|08   |20  |\n",
      "|18482  |70501974849 |68.75486276223054 |8505fb33-b69a-412a-a8e1-827983a66577|2021-08-20    |2021|08   |20  |\n",
      "|4      |49891706470 |48.89796461900801 |ed11e477-b09f-4ae0-84fb-74531ce8c30c|2021-08-20    |2021|08   |20  |\n",
      "|18482  |46804135891 |6.6168976971833615|05b5edb5-b925-414d-92da-ae71d3b9625e|2021-08-20    |2021|08   |20  |\n",
      "|7      |33064796871 |373.0873675184212 |fe188788-b89f-4dde-acc1-39cd91806c0d|2021-08-20    |2021|08   |20  |\n",
      "|18483  |44160392990 |83.98473054761176 |7c44302d-98b3-48be-809e-fb3d99a4d365|2021-08-20    |2021|08   |20  |\n",
      "|7      |68435002949 |232.5364986739752 |b4a89891-a113-45ef-ae78-ed413546c551|2021-08-20    |2021|08   |20  |\n",
      "|18484  |70033549200 |871.7678061729196 |4b1d941a-21a1-43ea-a972-55af2d236f38|2021-08-20    |2021|08   |20  |\n",
      "|7      |41944909975 |30.910755230234322|302ae628-8eba-4a52-b77f-9f8aedc906e8|2021-08-20    |2021|08   |20  |\n",
      "|18485  |41705715409 |309.5417224575787 |67f4f98e-3149-4e8f-b418-e726dce669eb|2021-08-20    |2021|08   |20  |\n",
      "|8      |29566626791 |74.15732460440282 |71a81652-cc91-4bf5-b1b0-b074ec72478d|2021-08-20    |2021|08   |20  |\n",
      "|18487  |32361057556 |119.19055863068847|15577921-1104-4704-a06d-9f73724b36c4|2021-08-20    |2021|08   |20  |\n",
      "|9      |47663262928 |36.69873283148887 |c4fcb49a-ce87-4e15-944e-0e6bdd660e8d|2021-08-20    |2021|08   |20  |\n",
      "+-------+------------+------------------+------------------------------------+--------------+----+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Splitting the 'order_datetime' column based on year, month, and date\n",
    "transactions = transactions.withColumn('year', split(transactions['order_datetime'], '-').getItem(0)) \\\n",
    "                           .withColumn('month', split(transactions['order_datetime'], '-').getItem(1)) \\\n",
    "                           .withColumn('date', split(transactions['order_datetime'], '-').getItem(2))\n",
    "transactions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide transactions according to year\n",
    "tx_2021 = transactions.filter(transactions.year == '2021')\n",
    "tx_2022 = transactions.filter(transactions.year == '2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|   07|\n",
      "|   05|\n",
      "|   08|\n",
      "|   06|\n",
      "|   04|\n",
      "|   03|\n",
      "|   02|\n",
      "|   11|\n",
      "|   12|\n",
      "|   09|\n",
      "|   10|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 255:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|   01|\n",
      "|   02|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find distinct month on both year '2021' and '2022'\n",
    "tx_2021.select('month').distinct().show()\n",
    "tx_2022.select('month').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17107"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count transactions monthly for year '2021'\n",
    "tx_02_2021 = tx_2021.select('month').where(tx_2021.month == 2).count()\n",
    "tx_03_2021 = tx_2021.select('month').where(tx_2021.month == 3).count()\n",
    "tx_04_2021 = tx_2021.select('month').where(tx_2021.month == 4).count()\n",
    "tx_05_2021 = tx_2021.select('month').where(tx_2021.month == 5).count()\n",
    "tx_06_2021 = tx_2021.select('month').where(tx_2021.month == 6).count()\n",
    "tx_07_2021 = tx_2021.select('month').where(tx_2021.month == 7).count()\n",
    "tx_08_2021 = tx_2021.select('month').where(tx_2021.month == 8).count()\n",
    "tx_09_2021 = tx_2021.select('month').where(tx_2021.month == 9).count()\n",
    "tx_10_2021 = tx_2021.select('month').where(tx_2021.month == 10).count()\n",
    "tx_11_2021 = tx_2021.select('month').where(tx_2021.month == 11).count()\n",
    "tx_12_2021 = tx_2021.select('month').where(tx_2021.month == 12).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count transactions monthly for year '2022'\n",
    "tx_01_2022 = tx_2022.select('month').where(tx_2022.month == 1).count()\n",
    "tx_02_2022 = tx_2022.select('month').where(tx_2022.month == 2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- transaction_frequency: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 269:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------------------+\n",
      "|year|month|transaction_frequency|\n",
      "+----+-----+---------------------+\n",
      "|2021|02   |17107                |\n",
      "|2021|03   |546333               |\n",
      "|2021|04   |560680               |\n",
      "|2021|05   |636666               |\n",
      "|2021|06   |627148               |\n",
      "|2021|07   |655279               |\n",
      "|2021|08   |688822               |\n",
      "|2021|09   |678524               |\n",
      "|2021|10   |729619               |\n",
      "|2021|11   |991226               |\n",
      "|2021|12   |957647               |\n",
      "|2022|01   |552478               |\n",
      "|2022|02   |509843               |\n",
      "+----+-----+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create new dataframe to store transaction frequency data\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "data = [('2021', '02', tx_02_2021), ('2021', '03', tx_03_2021), ('2021', '04', tx_04_2021), ('2021', '05', tx_05_2021),\n",
    "        ('2021', '06', tx_06_2021), ('2021', '07', tx_07_2021), ('2021', '08', tx_08_2021), ('2021', '09', tx_09_2021),\n",
    "        ('2021', '10', tx_10_2021), ('2021', '11', tx_11_2021), ('2021', '12', tx_12_2021), ('2022', '01', tx_01_2022),\n",
    "        ('2022', '02', tx_02_2022)]\n",
    "\n",
    "schema = StructType([\\\n",
    "    StructField('year',StringType(),True), \\\n",
    "    StructField('month',StringType(),True), \\\n",
    "    StructField('transaction_frequency',StringType(),True), \\\n",
    "        ])\n",
    "\n",
    "tx_frequency = spark.createDataFrame(data=data,schema=schema)\n",
    "tx_frequency.printSchema()\n",
    "tx_frequency.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Counting the number of unique customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT merchant_abn)|\n",
      "+----------------------------+\n",
      "|                        4406|\n",
      "+----------------------------+\n",
      "\n",
      "+----------------------------+\n",
      "|count(DISTINCT merchant_abn)|\n",
      "+----------------------------+\n",
      "|                        4166|\n",
      "+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculating the number of unique customers in year '2021' and '2022'\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "tx_2021.select(countDistinct('merchant_abn')).show()\n",
    "tx_2022.select(countDistinct('merchant_abn')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Calculate average transaction amount per merchant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 450:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/07 22:48:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks \n",
      "java.io.IOException: Failed to connect to /10.12.51.70:56489\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:126)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)\n",
      "\tat org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1144)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1088)\n",
      "\tat scala.Option.orElse(Option.scala:447)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1088)\n",
      "\tat org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1228)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Operation timed out: /10.12.51.70:56489\n",
      "Caused by: java.net.ConnectException: Operation timed out\n",
      "\tat sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:715)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:710)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roseline/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/roseline/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/roseline/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tz/df8fp5n961ndbt9j0zbzrlqc0000gn/T/ipykernel_30451/1151095264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_trx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_trx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Calculate the median of age from the population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### Calculate the mode of age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e620930cb2387514ed83d64398b9d779b3d32ded40344532af752d0dc8991f1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
