{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Categories Analysis\n",
    "#### 1. Proportion of revenue levels per tag\n",
    "#### 2. Mean, standard deviation, median dollar value per tag\n",
    "#### 3. Transaction frequency per tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. Number of unique merchants/consumers per tag - Andrew\n",
    "2. Age distribution by tag (add visualization) - Andrew\n",
    "3. Consumer income distribution by tag (add visualization) - Andrew\n",
    "4. Take rate * Dollar_Value - Andrew\n",
    "5. Unique SA2 per merchant - Patrick\n",
    "6. Analyze buying power (transaction frequency and monetary value) of SA2, possibly ranking weights to merchants by SA2 - Patrick\n",
    " 6.1 Add SA2 (Income, Age and Buying Power) Geospatial Visualization - Nadya\n",
    "7. Finalize features to use -> find correlation between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminchen/opt/anaconda3/envs/venv/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from pyspark.sql import SparkSession, Window, functions as F\n",
    "from pyspark.sql.functions import countDistinct, col, date_format\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import (\n",
    "    StringType,\n",
    "    LongType,\n",
    "    DoubleType,\n",
    "    StructField,\n",
    "    StructType,\n",
    "    FloatType\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 14:15:13 WARN Utils: Your hostname, Jas-Mins-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.9 instead (on interface en0)\n",
      "22/09/15 14:15:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 14:15:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Start Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2 BNPL\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BNPL dataset\n",
    "consumer = spark.read.csv(\"../data/tables/tbl_consumer.csv\", header=True, sep=\"|\")\n",
    "details = spark.read.parquet(\"../data/tables/consumer_user_details.parquet\")\n",
    "merchants = spark.read.parquet(\"../data/tables/tbl_merchants.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added transactions_20210228_20210827_snapshot\n",
      "added transactions_20210828_20220227_snapshot\n"
     ]
    }
   ],
   "source": [
    "# load all transactions datasets\n",
    "paths=['../data/tables/transactions_20210228_20210827_snapshot',\n",
    "       '../data/tables/transactions_20210828_20220227_snapshot']\n",
    "\n",
    "first = 1\n",
    "for path in paths:\n",
    "    if first:\n",
    "        transactions = spark.read.parquet(path)\n",
    "        print(f'added {path.split(\"/\")[3]}')\n",
    "        first = 0\n",
    "    else:\n",
    "        append_transactions = spark.read.parquet(path)\n",
    "        transactions = transactions.union(append_transactions)\n",
    "        print(f'added {path.split(\"/\")[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "../data/abs/sa2_age.gml: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/_shim.pyx:83\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../data/abs/sa2_age.gml: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasminchen/Library/Mobile Documents/com~apple~CloudDocs/2022/s2/MAST30034/generic-buy-now-pay-later-project-group-11/notebooks/product_categories_analysis_copy.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasminchen/Library/Mobile%20Documents/com~apple~CloudDocs/2022/s2/MAST30034/generic-buy-now-pay-later-project-group-11/notebooks/product_categories_analysis_copy.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m age \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mread_file(\u001b[39m\"\u001b[39;49m\u001b[39m../data/abs/sa2_age.gml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasminchen/Library/Mobile%20Documents/com~apple~CloudDocs/2022/s2/MAST30034/generic-buy-now-pay-later-project-group-11/notebooks/product_categories_analysis_copy.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m income \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mread_file(\u001b[39m\"\u001b[39m\u001b[39m../data/abs/sa2_income.gml\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/venv/lib/python3.8/site-packages/geopandas/io/file.py:201\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     reader \u001b[39m=\u001b[39m fiona\u001b[39m.\u001b[39mopen\n\u001b[1;32m    200\u001b[0m \u001b[39mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mwith\u001b[39;00m reader(path_or_bytes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m features:\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m         \u001b[39m# In a future Fiona release the crs attribute of features will\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39m# no longer be a dict, but will behave like a dict. So this should\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[39m# be forwards compatible\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         crs \u001b[39m=\u001b[39m (\n\u001b[1;32m    207\u001b[0m             features\u001b[39m.\u001b[39mcrs[\u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    208\u001b[0m             \u001b[39mif\u001b[39;00m features\u001b[39m.\u001b[39mcrs \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m features\u001b[39m.\u001b[39mcrs\n\u001b[1;32m    209\u001b[0m             \u001b[39melse\u001b[39;00m features\u001b[39m.\u001b[39mcrs_wkt\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    212\u001b[0m         \u001b[39m# handle loading the bounding box\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/venv/lib/python3.8/site-packages/fiona/env.py:408\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    406\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[39mif\u001b[39;00m local\u001b[39m.\u001b[39m_env:\n\u001b[0;32m--> 408\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    409\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/venv/lib/python3.8/site-packages/fiona/__init__.py:264\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     path \u001b[39m=\u001b[39m parse_path(fp)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 264\u001b[0m     c \u001b[39m=\u001b[39m Collection(path, mode, driver\u001b[39m=\u001b[39;49mdriver, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    265\u001b[0m                    layer\u001b[39m=\u001b[39;49mlayer, enabled_drivers\u001b[39m=\u001b[39;49menabled_drivers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    266\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m schema:\n\u001b[1;32m    268\u001b[0m         \u001b[39m# Make an ordered dict of schema properties.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/venv/lib/python3.8/site-packages/fiona/collection.py:162\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m Session()\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mstart(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:540\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_shim.pyx:90\u001b[0m, in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: ../data/abs/sa2_age.gml: No such file or directory"
     ]
    }
   ],
   "source": [
    "age = gpd.read_file(\"../data/abs/sa2_age.gml\")\n",
    "income = gpd.read_file(\"../data/abs/sa2_income.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load poa_to_sa2 dataset\n",
    "poa_to_sa2 = spark.read.csv(\"../data/curated/poa_w_sa2.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.agg({'order_datetime': 'max'}).show()\n",
    "transactions.agg({'order_datetime': 'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchants.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "merchants = merchants.withColumnRenamed('name', 'merchant_name')\n",
    "consumer = consumer.withColumnRenamed('name', 'consumer_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Merge transaction with consumer and merchant details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join consumers with their respective details\n",
    "consumer_detail = consumer.join(details, on=\"consumer_id\")\n",
    "\n",
    "# Join consumers with their respective transactions\n",
    "consumer_trx = consumer_detail.join(transactions, on=\"user_id\")\n",
    "\n",
    "# Join transactions with the respective merchants\n",
    "df_trx = consumer_trx.join(merchants, on=\"merchant_abn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trx.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poa_to_sa2.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trx.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate postcodes in transaction to sa2 codes\n",
    "sa2_cols = ['poa_name_2016', 'sa2_maincode_2016', 'sa2_name_2016', 'geometry']\n",
    "df_trx_sa2 = (df_trx \\\n",
    "                .join(poa_to_sa2[sa2_cols], \n",
    "                     on=[df_trx['postcode'] == poa_to_sa2['poa_name_2016']],\n",
    "                     how='inner')\n",
    "                .drop('poa_name_2016')\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trx.show(5, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore product tags for purchase frequency\n",
    "df_trx.groupby(\"tags\").count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "@F.udf(StringType())\n",
    "def normalize_tags(col):\n",
    "    return col.replace(\"(\", \"[\").replace(\")\", \"]\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"tags\", normalize_tags(F.col(\"tags\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"categories\", F.regexp_extract(\"tags\", \"(?<=\\[)(.*?)(?=\\])\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"revenue_level\", F.regexp_extract(\"tags\", \"(?<=,\\s\\[)([a-e]+?)(?=\\],)\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"take_rate\", F.regexp_extract(\"tags\", \"(?<=\\[take rate: )(.*?)(?=\\])\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"take_rate\", F.col(\"take_rate\").astype(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(StringType())\n",
    "def clean_string(col):\n",
    "    col = col.lower()\n",
    "    return \" \".join(col.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"categories\", clean_string(F.col(\"categories\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_take_rates = df_trx_sa2.select([\"categories\", \"revenue_level\", \"take_rate\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(category_take_rates[\"revenue_level\"], category_take_rates[\"take_rate\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue levels can be categorized by its take rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "category_take_rates.groupby([\"categories\", \"revenue_level\"]).size().agg(\n",
    "  {'count': lambda x: x, 'percent':lambda x: x / x.groupby(level=0).sum() * 100}\n",
    "  ).unstack(level=0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which categories provide the better amount in revenue for our BNPL company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_prices = df_trx_sa2.select([\"categories\", \"dollar_value\"]).toPandas()\n",
    "category_prices = category_prices[category_prices[\"dollar_value\"] >= 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_prices.groupby(\"categories\").agg([\"mean\", \"std\", \"median\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(category_prices[category_prices[\"categories\"] == \"telecom\"].loc[:,\"categories\"], \\\n",
    "    category_prices[category_prices[\"categories\"] == \"telecom\"].loc[:,\"dollar_value\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of unique merchants/consumers per tag - Andrew\n",
    "2. Age distribution by tag (add visualization) - Andrew\n",
    "3. Consumer income distribution by tag (add visualization) - Andrew\n",
    "4. Take rate * Dollar_Value - Andrew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of Unique Merchants and Consumer per Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2.groupby(\"categories\").agg(countDistinct(\"merchant_abn\"), countDistinct(\"consumer_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Revenue (Take Rate / 100 * Dollar Value) and taking the top 10 highest revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(FloatType())\n",
    "def get_revenue(take_rate, dollar_value):\n",
    "    return (take_rate / 100) * dollar_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trx_over35 = df_trx_sa2.where(F.col(\"dollar_value\") >= 35)\n",
    "trx_over35 = trx_over35.withColumn(\"revenue\", get_revenue(F.col(\"take_rate\"), F.col(\"dollar_value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_tag = trx_over35.groupby(\"categories\").mean(\"revenue\").sort(\"avg(revenue)\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_tags = revenue_per_tag.select(\"categories\").head(10)\n",
    "for i in range(len(top10_tags)):\n",
    "    top10_tags[i] = top10_tags[i].__getitem__('categories')\n",
    "\n",
    "top10_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_tag.limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Age distribution by tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag = df_trx_sa2.select(\"sa2_maincode_2016\", \"categories\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag[\"sa2_maincode_2016\"] = pd_age_tag[\"sa2_maincode_2016\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cols = [\"sa2_main16\", \"persons_age_20_24\", \"persons_age_25_29\" , \"persons_age_30_34\", \"persons_age_35_39\", \"persons_age_40_44\", \\\n",
    "    \"persons_age_45_49\", \"persons_age_50_54\", \"persons_age_55_59\", \"persons_age_60_64\", \"persons_age_65_69\", \"persons_age_70_74\", \\\n",
    "        \"persons_age_75_79\", \"persons_age_80_84\", \"persons_age_85_plus\"]\n",
    "\n",
    "pd_age_tag = pd_age_tag.merge(age[age_cols], left_on=\"sa2_maincode_2016\", right_on=\"sa2_main16\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag_final = pd_age_tag.groupby([\"categories\", \"sa2_main16\"]).mean().groupby(\"categories\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag_final[\"Total\"] = pd_age_tag_final.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in age_cols[1:]:\n",
    "    pd_age_tag_final[column] = pd_age_tag_final[column] / pd_age_tag_final[\"Total\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag_final = pd_age_tag_final.query(\"categories in @top10_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_age_tag_final.head(10)\n",
    "# Values displayed is the percentage of people in that age bracket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consumer income distribution by tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_cols = [\"sa2_code\", \"median_aud\"]\n",
    "pd_income_tag = pd_age_tag.merge(income[income_cols], left_on=\"sa2_maincode_2016\", right_on=\"sa2_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_income_tag_final = pd_income_tag.groupby([\"categories\", \"sa2_main16\"]).mean().groupby(\"categories\").agg({'median_aud': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_income_tag_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_income_tag_final = pd_income_tag_final.query(\"categories in @top10_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_income_tag_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median income for each tag is very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Unique SA2 per merchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate postcodes in transaction to sa2 codes\n",
    "sa2_cols = ['poa_name_2016', 'sa2_maincode_2016', 'sa2_name_2016', 'geometry']\n",
    "df_trx_sa2 = (df_trx \\\n",
    "                .join(poa_to_sa2[sa2_cols], \n",
    "                     on=[df_trx['postcode'] == poa_to_sa2['poa_name_2016']],\n",
    "                     how='inner')\n",
    "                .drop('poa_name_2016')\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nunique_sa2 = (df_trx_sa2.groupby('merchant_abn')\n",
    "                   .agg(countDistinct('sa2_maincode_2016')).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nunique_sa2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_nunique_sa2[\"count(sa2_maincode_2016)\"], \n",
    "            stat=\"density\", kde=True, bins=25)\n",
    "plt.title(f'Density Plot for \"count(sa2_maincode_2016)\"', fontsize=18)\n",
    "plt.xlabel(f'count(sa2_maincode_2016)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Unique consumer per merchant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nunique_con = (df_trx_sa2.groupby('merchant_abn')\n",
    "                   .agg(countDistinct('consumer_id')).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_nunique_con[\"count(consumer_id)\"], \n",
    "            stat=\"density\", kde=True, bins=25)\n",
    "plt.title(f'Density Plot for \"count(consumer_id)\"', fontsize=18)\n",
    "plt.xlabel(f'count(consumer_id)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Analyze buying power (transaction frequency and monetary value) of SA2, possibly ranking weights to merchants by SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(df_trx_sa2.groupby(['sa2_maincode_2016'])\n",
    "               .agg(func.mean('dollar_value'))\n",
    "               .sort(['sa2_maincode_2016']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_trx = (df_trx_sa2.groupby(['sa2_maincode_2016', 'state'])\n",
    "             .agg({'order_id':'count', 'dollar_value':'sum'})\n",
    "             .sort(['sa2_maincode_2016', 'state']))\n",
    "unique_cons = (df_trx_sa2.groupby(['sa2_maincode_2016', 'state'])\n",
    "               .agg(countDistinct('consumer_id'))\n",
    "               .sort(['sa2_maincode_2016', 'state']))\n",
    "unique_merc = (df_trx_sa2.groupby(['sa2_maincode_2016', 'state'])\n",
    "               .agg(countDistinct('merchant_abn'))\n",
    "               .sort(['sa2_maincode_2016', 'state']))\n",
    "avg_trx_val = (df_trx_sa2.groupby(['sa2_maincode_2016', 'state'])\n",
    "               .agg(func.mean('dollar_value'))\n",
    "               .sort(['sa2_maincode_2016', 'state']))\n",
    "\n",
    "def join_agg(sdf1, sdf2):\n",
    "    '''\n",
    "        take two dataframes and join the two dataframes\n",
    "    '''\n",
    "    sdf1 = (sdf1.alias(\"a\") \\\n",
    "               .join(sdf2, \n",
    "                     on=['sa2_maincode_2016', 'state'], \n",
    "                     how='inner')\n",
    "           )\n",
    "    return sdf1\n",
    "df_buy_pow = join_agg(sa2_trx, unique_cons)\n",
    "df_buy_pow = join_agg(df_buy_pow, unique_merc)\n",
    "df_buy_pow = join_agg(df_buy_pow, avg_trx_val)\n",
    "    \n",
    "# renaming a few columns\n",
    "field_name_change = {\"sum(dollar_value)\": \"total_dollar_value\",\n",
    "                     \"avg(dollar_value)\": \"avg_dollar_value\",\n",
    "                     \"count(order_id)\": \"transaction_freq\",\n",
    "                     \"count(consumer_id)\": \"n_unique_consumer\",\n",
    "                     \"count(merchant_abn)\": \"n_unique_merchant\"}\n",
    "for old, new in field_name_change.items():\n",
    "    df_buy_pow = df_buy_pow.withColumnRenamed(old, new)\n",
    "\n",
    "cols = ['sa2_maincode_2016', 'state', 'n_unique_consumer', 'transaction_freq', \n",
    "        'total_dollar_value', 'avg_dollar_value', 'n_unique_merchant']\n",
    "df_buy_pow = df_buy_pow[cols].sort(['sa2_maincode_2016'])\n",
    "\n",
    "df_buy_pow = (df_buy_pow.\n",
    "             withColumn('spending_per_customer', \n",
    "                        col(\"total_dollar_value\") / col(\"n_unique_consumer\")))\n",
    "\n",
    "df_buy_pow = (df_buy_pow.\n",
    "             withColumn('num_trx_per_customer', \n",
    "                        col(\"transaction_freq\") / col(\"n_unique_consumer\")))\n",
    "\n",
    "df_buy_pow = (df_buy_pow.\n",
    "             withColumn('sales_per_merchant', \n",
    "                        col(\"total_dollar_value\") / col(\"n_unique_merchant\")))\n",
    "\n",
    "df_buy_pow = (df_buy_pow.\n",
    "             withColumn('num_trx_per_merchant', \n",
    "                        col(\"transaction_freq\") / col(\"n_unique_merchant\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy_pow.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fields = ['n_unique_consumer', 'transaction_freq', 'total_dollar_value',\n",
    "          'n_unique_merchant', 'spending_per_customer', 'num_trx_per_customer',\n",
    "          'sales_per_merchant', 'num_trx_per_merchant', 'avg_dollar_value']\n",
    "\n",
    "# get the distribution plot for the selected metrics\n",
    "for field in fields:\n",
    "    print(f'Distribution for {field}')\n",
    "    df_field = df_buy_pow[[field]].toPandas()\n",
    "\n",
    "    print(f'Minimum {field} by SA2: {df_field.min()[0]}')\n",
    "    print(f'Median {field} by SA2: {df_field.median()[0]}')\n",
    "    print(f'Maximum {field} by SA2: {df_field.max()[0]}')\n",
    "\n",
    "    sns.displot(df_field[field], \n",
    "                stat=\"density\", kde=True, bins=25)\n",
    "    plt.title(f'Density Plot for {field}', fontsize=15)\n",
    "    plt.xlabel(f'{field}')\n",
    "    plt.show()\n",
    "    \n",
    "    print('---' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank SA2 with the highest buying power (spending per customer)\n",
    "(df_buy_pow[['sa2_maincode_2016', 'state', 'spending_per_customer']]\n",
    "            .sort('spending_per_customer', ascending=False).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank SA2 with the highest average transaction value (avg_dollar_value)\n",
    "(df_buy_pow[['sa2_maincode_2016', 'state', 'avg_dollar_value']]\n",
    "            .sort('avg_dollar_value', ascending=False).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank SA2 with the highest transaction frequency (num_trx_per_customer)\n",
    "(df_buy_pow[['sa2_maincode_2016', 'state', 'num_trx_per_customer']]\n",
    "            .sort('num_trx_per_customer', ascending=False).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the table above by taking one SA2 code\n",
    "(df_trx_sa2.filter(F.col('sa2_maincode_2016') == 309031239.0)\n",
    " .groupby('consumer_id').agg({\n",
    "                               'order_id':'count',\n",
    "                               'dollar_value': 'sum' \n",
    "                            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate population of male/female with age above 20\n",
    "left_age = 25\n",
    "right_age = 29\n",
    "age['males_above_20'] = age['males_age_20_24']\n",
    "age['females_above_20'] = age['females_age_20_24']\n",
    "age['persons_above_20'] = age['persons_age_20_24']\n",
    "\n",
    "while right_age < 89:\n",
    "    if right_age == 89:\n",
    "        right_age = 'plus'\n",
    "\n",
    "    age['males_above_20'] += age[f'males_age_{left_age}_{right_age}']\n",
    "    age['females_above_20'] += age[f'females_age_{left_age}_{right_age}']\n",
    "    age['persons_above_20'] += age[f'persons_age_{left_age}_{right_age}']\n",
    "    \n",
    "    left_age += 5\n",
    "    right_age += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_buy_pow = df_buy_pow.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge df_trx_sa2 with income, age, and population\n",
    "income['sa2_code'] = income['sa2_code'].astype('float').astype('str')\n",
    "income_col = ['sa2_code', 'median_aud', 'earners_persons', \n",
    "              'median_age_of_earners_years']\n",
    "pdf_buy_pow = pdf_buy_pow.merge(income[income_col],\n",
    "                                left_on='sa2_maincode_2016',\n",
    "                                right_on='sa2_code', how='left')\n",
    "\n",
    "age['sa2_main16'] = age['sa2_main16'].astype('float').astype('str')\n",
    "age_col = ['sa2_main16', 'males_above_20', \n",
    "           'females_above_20', 'persons_above_20']\n",
    "pdf_buy_pow = pdf_buy_pow.merge(age[age_col],\n",
    "                                left_on='sa2_maincode_2016',\n",
    "                                right_on='sa2_main16', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_buy_pow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation between features of interest\n",
    "fields = ['n_unique_consumer', 'transaction_freq', 'total_dollar_value',\n",
    "          'n_unique_merchant', 'spending_per_customer', 'num_trx_per_customer',\n",
    "          'sales_per_merchant', 'num_trx_per_merchant', 'median_aud', \n",
    "          'earners_persons', 'median_age_of_earners_years', \n",
    "          'males_above_20', 'females_above_20', 'persons_above_20']\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(pdf_buy_pow[fields].corr(method='pearson'), \n",
    "            vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "\n",
    "plt.title('Pearson Correlation Metrics', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue by SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx_sa2 = df_trx_sa2.withColumn(\"revenue\",\n",
    "                                   get_revenue(F.col(\"take_rate\"), \n",
    "                                               F.col(\"dollar_value\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"sa2_maincode_2016\", \"state\", \"revenue\"]\n",
    "\n",
    "revenue_sa2 = (df_trx_sa2[cols].groupby([\"sa2_maincode_2016\", \"state\"])\n",
    "               .agg(func.mean(\"revenue\"), func.sum(\"revenue\")))\n",
    "\n",
    "revenue_sa2.sort(\"avg(revenue)\", ascending=False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### SA2 (Income, Age and Buying Power) Geospatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poa_to_sa2_pd = pd.read_csv(\"../data/curated/poa_w_sa2.csv\")\n",
    "poa_to_sa2_pd = poa_to_sa2_pd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "poa_to_sa2_pd['geometry'] = poa_to_sa2_pd['geometry'].astype('str').apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(poa_to_sa2_pd, crs='epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['geometry'] = gdf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a JSON \n",
    "geoJSON = gdf[['sa2_maincode_2016', 'geometry']].drop_duplicates('sa2_maincode_2016').to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Income by SA2 Geospatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_income_tag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pd_income_tag, \n",
    "    columns = ['sa2_maincode_2016', 'median_aud'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Income by SA2 Area'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Age by SA2 Geospatial Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pd_age_tag, \n",
    "    columns = ['sa2_maincode_2016', 'persons_age_20_24'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Income by SA2 Area'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pd_age_tag, \n",
    "    columns = ['sa2_maincode_2016', 'persons_age_30_34'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Income by SA2 Area'))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pd_age_tag, \n",
    "    columns = ['sa2_maincode_2016', 'persons_age_40_44'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Income by SA2 Area'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Buying Power by SA2 Geospatial Visualization\n",
    "a. Number of Transaction per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pdf_buy_pow, \n",
    "    columns = ['sa2_maincode_2016', 'num_trx_per_customer'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Buying Power (Number of Transactions per Customer) by SA2'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Spending per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[-38.043995, 145.264296], tiles=\"Stamen Terrain\", zoom_start=8)\n",
    "m.add_child(folium.Choropleth(\n",
    "    geo_data=geoJSON, # geoJSON \n",
    "    data=pdf_buy_pow, \n",
    "    columns = ['sa2_maincode_2016', 'spending_per_customer'], \n",
    "    key_on = 'properties.sa2_maincode_2016', \n",
    "    fill_color='YlGnBu', \n",
    "    name='choropleth', \n",
    "    legend_name='Income by SA2 Area'))\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "33aa29f69ca689f3496ffd58455a4abcce4817c6814cca6a6bb98c21c2d7ad06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
